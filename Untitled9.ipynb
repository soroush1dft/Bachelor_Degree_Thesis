{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUuaSftjZYJqQcdAefReOS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soroush1dft/Bachelor_Degree_Thesis/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeI5Lbp7uKLc",
        "outputId": "9bc5e124-fb3f-4111-ef40-e33833fd7b39"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Read and preprocess the text data\n",
        "def read_and_preprocess(file_path):\n",
        "    with open(file_path, \"r\", encoding='utf-8') as file:\n",
        "        content = file.read().lower()\n",
        "    # Remove punctuation\n",
        "    content = re.sub(r'[^\\w\\s]', '', content)\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(content)\n",
        "\n",
        "    # Remove Stopwords\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Join the tokens back into a string\n",
        "    filtered_content = ' '.join(filtered_tokens)\n",
        "\n",
        "    return filtered_content\n",
        "\n",
        "# Extract top N keywords from the text\n",
        "def extract_top_keywords(content, top_n=20):\n",
        "    words = content.split()\n",
        "    word_counts = Counter(words)\n",
        "    top_keywords = word_counts.most_common(top_n)\n",
        "    return top_keywords\n",
        "\n",
        "# Find common keywords between two lists of keywords\n",
        "def find_common_keywords(keywords1, keywords2):\n",
        "    set1 = {word for word, _ in keywords1}\n",
        "    set2 = {word for word, _ in keywords2}\n",
        "    common = set1.intersection(set2)\n",
        "    return sorted(common)  # Return sorted list for consistent order\n",
        "\n",
        "# Construct the term-document matrix\n",
        "def construct_term_document_matrix(texts, keywords):\n",
        "    matrix = np.zeros((len(texts), len(keywords)))\n",
        "    for i, text in enumerate(texts):\n",
        "        word_counts = Counter(text.split())\n",
        "        for j, keyword in enumerate(keywords):\n",
        "            matrix[i][j] = word_counts[keyword]\n",
        "    return matrix\n",
        "\n",
        "\n",
        "# File paths\n",
        "txt_AlicesAdventuresinWonderland = \"LewisCarroll-AlicesAdventuresinWonderland.txt\"\n",
        "txt_ThroughtheLookingGlass = \"LewisCarroll-ThroughtheLooking-Glass.txt\"\n",
        "\n",
        "# Read and preprocess texts\n",
        "content_Alices = read_and_preprocess(txt_AlicesAdventuresinWonderland)\n",
        "content_Through = read_and_preprocess(txt_ThroughtheLookingGlass)\n",
        "\n",
        "# Extract top 20 keywords from each text\n",
        "top_keywords_Alices = extract_top_keywords(content_Alices, 1000)\n",
        "top_keywords_Through = extract_top_keywords(content_Through, 1000)\n",
        "\n",
        "# Find common keywords\n",
        "common_keywords = find_common_keywords(top_keywords_Alices, top_keywords_Through)\n",
        "common_top_n_keywords = common_keywords[:200]  # Take the top 20 common keywords\n",
        "\n",
        "# Construct term-document matrix\n",
        "tdm = construct_term_document_matrix([content_Alices, content_Through], common_top_n_keywords)\n",
        "\n",
        "print(\"Common Top 20 Keywords:\", common_top_n_keywords)\n",
        "print(\"Term-Document Matrix:\\n\", tdm)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qmQmlVguQuM",
        "outputId": "b42dccd7-80bf-4f7c-cb20-7942ba12460e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common Top 20 Keywords: ['across', 'added', 'afraid', 'afterwards', 'age', 'ah', 'air', 'alice', 'alices', 'alive', 'almost', 'alone', 'along', 'aloud', 'always', 'among', 'angrily', 'angry', 'another', 'answer', 'answered', 'anxious', 'anxiously', 'anything', 'argument', 'arm', 'arms', 'ask', 'asked', 'asking', 'asleep', 'away', 'back', 'beat', 'beautiful', 'beg', 'began', 'begin', 'beginning', 'begun', 'behind', 'believe', 'besides', 'best', 'better', 'bird', 'birds', 'bit', 'body', 'book', 'box', 'breadandbutter', 'breath', 'bright', 'bring', 'brought', 'business', 'cake', 'call', 'called', 'came', 'cant', 'care', 'carefully', 'case', 'catch', 'caught', 'certain', 'certainly', 'chance', 'changed', 'chapter', 'child', 'children', 'chorus', 'civil', 'close', 'come', 'comes', 'coming', 'consider', 'continued', 'conversation', 'corner', 'could', 'couldnt', 'course', 'crab', 'creature', 'creatures', 'cried', 'crossed', 'crown', 'cry', 'curiosity', 'curious', 'cut', 'dare', 'dark', 'day', 'days', 'dead', 'deal', 'dear', 'deep', 'deeply', 'delight', 'didnt', 'different', 'difficulty', 'dinah', 'direction', 'directions', 'dish', 'distance', 'doesnt', 'done', 'dont', 'door', 'doubt', 'draw', 'dream', 'drew', 'drink', 'dry', 'eager', 'eagerly', 'ear', 'ears', 'easily', 'eat', 'edge', 'either', 'else', 'em', 'end', 'english', 'enough', 'even', 'ever', 'every', 'everybody', 'everything', 'exactly', 'exclaimed', 'eye', 'eyes', 'face', 'faces', 'fact', 'fall', 'falling', 'far', 'fast', 'faster', 'fear', 'feather', 'feel', 'feeling', 'feet', 'fell', 'felt', 'find', 'finger', 'finished', 'fire', 'first', 'fish', 'fit', 'five', 'floor', 'flowers', 'fond', 'forgetting', 'found', 'four', 'french', 'friend', 'frightened', 'full', 'fun', 'game', 'garden', 'gave', 'generally', 'gently', 'get', 'getting', 'girl', 'give', 'glad', 'glass', 'go', 'goes', 'going', 'gone', 'good', 'got', 'grand', 'grass']\n",
            "Term-Document Matrix:\n",
            " [[  5.  23.  12.   2.   4.   6.  14. 385.  12.   3.   6.   4.   5.   5.\n",
            "   12.  12.   9.   6.  22.   9.   5.   3.  14.  19.   4.  12.   7.  11.\n",
            "   17.   5.   8.  25.  40.   4.  14.   9.  59.  14.  13.   7.  13.  10.\n",
            "    4.  12.  14.   3.   9.  16.   3.   7.   4.   6.   5.   7.   3.   3.\n",
            "    7.   3.   9.  16.  40.  28.   4.   3.   5.   3.   3.   3.  14.   4.\n",
            "    8.  12.  10.  10.   6.   3.  13.  46.   3.  10.   4.   7.   9.   3.\n",
            "   78.   9.  25.   3.   4.  11.  20.   3.   3.   4.   5.  19.   5.   5.\n",
            "    3.  25.   4.   4.  12.  29.   7.   4.   3.  14.   9.   4.  12.   5.\n",
            "    3.   3.   7.  16.  16.  60.  29.   4.   7.   7.   5.   7.   8.   3.\n",
            "    8.   6.   5.   3.  18.   3.  10.  10.   3.  18.   6.  17.  18.  23.\n",
            "   14.   7.  10.   8.   6.   7.  27.  14.   5.   8.   7.   2.  13.   4.\n",
            "    3.   4.   2.   8.   7.  19.   6.  23.  21.   5.  10.   3.  49.   3.\n",
            "    3.   8.   3.   3.   3.   3.  32.   6.   4.   3.   7.   7.   3.  12.\n",
            "   15.  15.   7.   3.  46.  22.   4.  12.  11.   9.  50.   7.  26.  13.\n",
            "   24.  47.   3.   4.]\n",
            " [  8.  21.  15.  13.   4.   4.  15. 441.  21.   5.  11.   5.  15.   5.\n",
            "   30.  16.   4.   5.  32.  22.   5.   6.   8.  18.   7.   5.  12.  13.\n",
            "   28.   5.   4.  36.  32.   3.   7.   5.  48.  18.  16.   5.  10.  13.\n",
            "    4.  16.  31.   3.   4.  11.   4.   8.   6.   6.  17.   8.   4.   4.\n",
            "    3.   4.  15.  15.  49.  38.   8.   5.   3.   4.  10.   6.  10.   3.\n",
            "    3.  24.  16.   3.   7.   4.  12.  50.   6.  11.   6.   3.   9.   3.\n",
            "   71.  37.  34.   4.   8.   5.  56.   5.   9.   8.   5.   8.  10.   3.\n",
            "    9.  17.   7.   4.   9.  25.   5.   3.   6.  37.   6.   4.   9.   4.\n",
            "    3.  12.   3.  11.  17.  78.  15.   3.   3.  13.   5.   4.   4.   5.\n",
            "    9.  15.   4.   4.   3.   4.   4.  11.   5.  16.   3.  18.  16.  22.\n",
            "   18.   6.   7.  13.   8.   5.  40.  20.   4.   7.  11.   6.  13.  17.\n",
            "   10.   7.   6.   6.   5.  18.  12.  17.  21.   8.   6.   8.  33.   8.\n",
            "    4.  10.   3.   9.   3.   3.  19.  10.   3.   3.  14.  12.   6.   7.\n",
            "    9.  16.   7.  14.  49.  28.   3.  13.  10.   6.  58.  11.  22.   7.\n",
            "   28.  67.   7.   3.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now its time to convert it to np.array"
      ],
      "metadata": {
        "id": "vFHUZc8uvdyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "tdm_np_array = np.array(tdm)"
      ],
      "metadata": {
        "id": "YQ65UvqYvda7"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_term_document_matrix_for_input(input_string, common_top_n_keywords):\n",
        "    # Preprocess the input string\n",
        "    input_string = input_string.lower()  # Lowercase the text\n",
        "    input_string = re.sub(r'[^\\w\\s]', '', input_string)  # Remove punctuation\n",
        "    tokens = word_tokenize(input_string)  # Tokenize\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
        "\n",
        "    # Construct the term-document matrix for the input\n",
        "    matrix = np.zeros((1, len(common_top_n_keywords)))\n",
        "    word_counts = Counter(filtered_tokens)\n",
        "    for j, keyword in enumerate(common_top_n_keywords):\n",
        "        matrix[0][j] = word_counts[keyword]\n",
        "\n",
        "    return matrix"
      ],
      "metadata": {
        "id": "5ax9Qg9TxLt4"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_input_toTDM = input(\"Please enter any string to calcualate its Term Document Matrix:\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEAOsjq0xiyL",
        "outputId": "c79af562-cca0-43a1-f474-3dddcd241ddb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter any string to calcualate its Term Document Matrix:\n",
            "CHAPTER II.   THE POOL OF TEARS.   \"Curiouser and curiouser!\" cried Alice (she was so much surprised, that for the moment she quite forgot how to speak good English); \"now I'm opening out like the largest telescope that ever was! Good-bye, feet!\" (for when she looked down at her feet, they seemed to be almost out of sight, they were getting so far off). \"Oh, my poor little feet, I wonder who will put on your shoes and stockings for you now, dears? I'm sure I shan't be able! I shall be a great deal too far off to trouble myself about you: you must manage the best way you can;—but I must be kind to them,\" thought Alice, \"or perhaps they won't walk the way I want to go! Let me see: I'll give them a new pair of boots every Christmas.\"  And she went on planning to herself how she would manage it. \"They must go by the carrier,\" she thought; \"and how funny it'll seem, sending presents to one's own feet! And how odd the directions will look!  Alice's Right Foot, Esq. Hearthrug, near the Fender, (with Alice's love.)  Oh dear, what nonsense I'm talking!\"  Just at this moment her head struck against the roof of the hall: in fact she was now rather more than nine feet high, and she at once took up the little golden key and hurried off to the garden door.  Poor Alice! It was as much as she could do, lying down on one side, to look through into the garden with one eye; but to get through was more hopeless than ever: she sat down and began to cry again.  \"You ought to be ashamed of yourself,\" said Alice, \"a great girl like you,\" (she might well say this,) \"to go on crying in this way! Stop this moment, I tell you!\" But she went on all the same, shedding gallons of tears, until there was a large pool all round her, about four inches deep and reaching half down the hall. After a time she heard a little pattering of feet in the distance, and she hastily dried her eyes to see what was coming. It was the White Rabbit returning, splendidly dressed, with a pair of white kid gloves in one hand and a large fan in the other: he came trotting along in a great hurry, muttering to himself as he came, \"Oh! the Duchess, the Duchess! Oh! won't she be savage if I've kept her waiting!\" Alice felt so desperate that she was ready to ask help  of any one; so, when the Rabbit came near her, she began, in a low, timid voice, \"If you please, sir——\" The Rabbit started violently, dropped the white kid gloves and the fan, and skurried away into the darkness as hard as he could go.  Alice took up the fan and gloves, and, as the hall was very hot, she kept fanning herself all the time she went on talking: \"Dear, dear! How queer everything is to-day! And yesterday things went on just as usual. I wonder if I've been changed in the night? Let me think: was I the same when I got up this morning? I almost think I can remember feeling a little different. But if I'm not the same, the next question is. Who in the world am I? Ah, that's the great puzzle!\" And she began thinking over all the children she knew, that were of the same age as herself, to see if she could have been changed for any of them.  \"I'm sure I'm not Ada,\" she said, \"for her hair goes in such long ringlets, and mine doesn't go in ringlets at all; and I'm sure I can't be Mabel, for I know all sorts of things, and she, oh! she knows such a very little! Besides, she's she, and I'm I, and—oh dear, how puzzling it all is! I'll try if I know all the things I used to know. Let me see: four times five is twelve, and four times six is thirteen, and four times seven is—oh dear! I shall never get to twenty at that rate! However, the Multiplication Table doesn't signify: let's try Geography. London is the capital of Paris, and Paris is the capital of Rome, and Rome—no, that's all wrong, I'm certain! I must have been changed for Mabel! I'll try and say 'How doth the little—'\" and she crossed her hands on her lap as if she were saying lessons, and began to repeat it, but her voice sounded hoarse and strange, and the words did not come the same as they used to do:—   \"How doth the little crocodile  Improve his shining tail, And pour the waters of the Nile  On every golden scale!   \"How cheerfully he seems to grin,  How neatly spreads his claws, And welcomes little fishes in  With gently smiling jaws!\"   \"I'm sure those are not the right words,\" said poor Alice, and her eyes filled with tears again as she went on, \"I must be Mabel after all, and I shall have to go and live in that poky little house, and have next to no toys to play with, and oh! ever so many lessons to learn! No, I've made up my mind about it; if I'm Mabel, I'll stay down here! It'll be no use their putting their heads down and saying, 'Come up again, dear!' I shall only look up and say, 'Who am I then? Tell me that first, and then, if I like being that person, I'll come up: if not, I'll stay down here till I'm somebody else'—but, oh dear!\" cried Alice, with a sudden burst of tears, \"I do wish they would put their heads down! I am so very tired of being all alone here!\"  As she said this she looked down at her hands, and was surprised to see that she had put on one of the Rabbit's little white kid gloves while she was talking. \"How can I have done that?\" she thought. \"I must be growing small again.\" She got up and went to the table to measure herself by it, and found that, as nearly as she could guess, she was now about two feet high, and was going on shrinking rapidly: she soon found out that the cause of this was the fan she was holding, and she dropped it hastily, just in time to save herself from shrinking away altogether.  \"That was a narrow escape!\" said Alice, a good deal frightened at the sudden change, but very glad to find herself still in existence; \"and now for the garden!\" and she ran with all speed back to the little door: but, alas! the little door was shut again, and the little golden key was lying on the glass table as before, \"and things are worse than ever,\" thought the poor child, \"for I never was so small as this before, never! And I declare it's too bad, that it is!\" As she said these words her foot slipped, and in another moment, splash! she was up to her chin in salt water. Her first idea was that she had somehow fallen into the sea, \"and in  that case I can go back by railway,\" she said to herself. (Alice had been to the seaside once in her life, and had come to the general conclusion, that wherever you go to on the English coast you find a number of bathing machines in the sea, some children digging in the sand with wooden spades, then a row of lodging houses, and behind them a railway station.) However, she soon made out that she was in the pool of tears which she had wept when she was nine feet high.  \"I wish I hadn't cried so much!\" said Alice, as she swam about, trying to find her way out. \"I shall be punished for it now, I suppose, by being drowned in my own tears! That will be a queer thing, to be sure! However, everything is queer to-day.\"  Just then she heard something splashing about in the pool a little way off, and she swam nearer to make out what it was: at first she thought it must be a walrus or hippopotamus, but then she remembered how small she was now, and she soon made out that it was only a mouse that had slipped in like herself.  \"Would it be of any use, now,\" thought Alice, \"to speak to this mouse? Everything is so out-of-the-way down here, that I should think very likely it can talk: at any rate, there's no harm in trying.\" So she began: \"O Mouse, do you know the way out of this pool? I am very tired of swimming about here, O Mouse!\" (Alice thought this must be the right way of speaking to a mouse: she had never done such a thing before, but she remembered having seen in her brother's Latin Grammar, \"A a mouse—to a mouse—A mouse—O mouse!\") The Mouse looked at her rather inquisitively, and seemed to her to wink with one of its little eyes, but it said nothing.  \"Perhaps it doesn't understand English,\" thought Alice; \"I daresay it's a French mouse, come over with William the Conqueror.\" (For, with all her knowledge of history, Alice had no very clear notion how long ago anything had happened.) So she began again: \"Où est ma chatte?\" which was the first sentence in her French lesson-book. The Mouse gave a sudden leap out of the water, and seemed to quiver all over with fright. \"Oh, I beg your pardon!\" cried Alice hastily, afraid that she had hurt the poor animal's feelings. \"I quite forgot you didn't like cats.\"  \"Not like cats!\" cried the Mouse, in a shrill, passionate voice. \"Would you like cats if you were me?\" \"Well, perhaps not,\" said Alice in a soothing tone: \"don't be angry about it. And yet I wish I could show you our cat Dinah: I think you'd take a fancy to cats if you could only see her. She is such a dear quiet thing,\" Alice went on, half to herself, as she swam lazily about in the pool, \"and she sits purring so nicely by the fire, licking her paws and washing her face—and she is such a nice soft thing to nurse—and she's such a capital one for catching mice——oh, I beg your pardon!\" cried Alice again, for this time the Mouse was bristling all over, and she felt certain it must be really offended. \"We won't talk about her any more if you'd rather not.\"  \"We, indeed!\" cried the Mouse, who was trembling down to the end of his tail. \"As if I would talk on such a subject! Our family always hated cats: nasty, low, vulgar things! Don't let me hear the name again!\"  \"I wont indeed!\" said Alice, in a great hurry to change the subject of conversation. \"Are you—are you fond—of—of dogs?\" The Mouse did not answer, so Alice went on eagerly: \"There is such a nice little dog near our house I should like to show you! A little bright-eyed terrier, you know, with oh! such long curly brown hair! And it'll fetch things when you throw them, and it'll sit up and beg for its dinner, and all sorts of things—I can't remember half of them—and it belongs to a farmer, you know, and he says it's so useful, it's worth a hundred pounds! He says it kills all the rats and—oh dear!\" cried Alice in a sorrowful tone. \"I'm afraid I've offended it again!\" For the Mouse was swimming away from her as hard as it could go, and making quite a commotion in the pool as it went.  So she called softly after it: \"Mouse dear! Do come back again, and we won't talk about cats or dogs either, if you don't like them! \" When the Mouse heard this, it turned round and swam slowly back to her: its face was quite pale (with passion, Alice thought), and it said in a low, trembling voice, \"Let us get to the shore, and then I'll tell you my history, and you'll understand why it is I hate cats and dogs.\"  It was high time to go, for the pool was getting quite crowded with the birds and animals that had fallen into it: there were a Duck and a Dodo, a Lory and an Eaglet, and several other curious creatures. Alice led the way, and the whole party swam to the shore.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(calculate_term_document_matrix_for_input(string_input_toTDM, common_top_n_keywords))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG_A2ebVyRa-",
        "outputId": "4afe2203-edb8-4fd9-de03-b551346445dd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  0.  2.  0.  1.  1.  0. 24.  2.  0.  2.  1.  1.  0.  1.  0.  0.  1.\n",
            "   1.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  3.  4.  0.  0.  3.\n",
            "   6.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.  0.  1.  3.  2.  0.  0.  1.  0.  0.  2.  0.  0.  3.  1.\n",
            "   1.  2.  0.  0.  0.  6.  0.  1.  0.  0.  1.  0.  7.  0.  0.  0.  0.  1.\n",
            "   8.  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  2. 10.  1.  0.  0.  1.\n",
            "   1.  0.  1.  0.  1.  0.  1.  3.  2.  3.  3.  0.  0.  0.  0.  0.  0.  0.\n",
            "   1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  3.  0.  0.  4.  2.  0.  3.  0.\n",
            "   0.  1.  3.  1.  0.  1.  0.  0.  2.  0.  0.  0.  0.  0.  1.  8.  0.  2.\n",
            "   3.  0.  0.  1.  4.  0.  0.  1.  0.  0.  0.  0.  2.  4.  2.  0.  1.  0.\n",
            "   0.  0.  3.  1.  0.  1.  3.  2.  1.  1.  1.  1. 10.  1.  1.  0.  2.  2.\n",
            "   0.  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import norm\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"Calculate the cosine similarity between two vectors.\"\"\"\n",
        "    return np.dot(vec1, vec2) / (norm(vec1, 2) * norm(vec2, 2))\n",
        "\n",
        "def classify_text(input_string, common_top_20_keywords, tdm):\n",
        "    # Calculate the term-document matrix for the input\n",
        "    input_tdm = calculate_term_document_matrix_for_input(input_string, common_top_20_keywords)\n",
        "\n",
        "    # Compare with Alice's Adventures in Wonderland (column 0) and Through the Looking-Glass (column 1)\n",
        "    similarity_Alices = cosine_similarity(input_tdm[0], tdm[0])\n",
        "    similarity_Through = cosine_similarity(input_tdm[0], tdm[1])\n",
        "    result = \"\"\n",
        "    # Classification based on higher cosine similarity\n",
        "    if similarity_Alices > similarity_Through:\n",
        "        result = \"The input text is more similar to Alice's Adventures in Wonderland.\"\n",
        "    else:\n",
        "        result = \"The input text is more similar to Through the Looking-Glass.\"\n",
        "    return result"
      ],
      "metadata": {
        "id": "W-zVIRFEyxoa"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_txt = classify_text(string_input_toTDM, common_top_n_keywords, tdm)\n",
        "print(test_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cff-F4dV0nXV",
        "outputId": "c8e11ada-af0a-4a35-e9ac-90a35d9c495d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input text is more similar to Alice's Adventures in Wonderland.\n"
          ]
        }
      ]
    }
  ]
}